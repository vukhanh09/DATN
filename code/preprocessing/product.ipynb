{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7975e572",
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import loads\n",
    "from pyspark.sql import SparkSession\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from pyspark.sql.functions import col,from_json,udf,explode\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType,MapType,FloatType,ArrayType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72859791",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/11/27 06:06:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.\\\n",
    "        builder.\\\n",
    "        appName(\"process-data\").\\\n",
    "        master(\"spark://spark-master:7077\").\\\n",
    "        config(\"spark.executor.memory\", \"1024m\").\\\n",
    "        getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5929d4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data = spark.read.parquet('hdfs://namenode:9000/tiki/Product')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c85f3160",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sample_data = data.select('value').take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2e1e293",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample = [loads(item.value) for item in sample_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7e8ec1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([ \n",
    "    StructField(\"id\",IntegerType(),True), \n",
    "    StructField(\"master_id\",IntegerType(),True), \n",
    "    StructField(\"sku\",StringType(),True), \n",
    "    StructField(\"name\",StringType(),True),\n",
    "    StructField(\"short_description\",StringType(),True), \n",
    "    StructField(\"price\",IntegerType(),True),\n",
    "    StructField(\"list_price\",IntegerType(),True),\n",
    "    StructField('original_price', IntegerType(),True),\n",
    "    StructField('discount', IntegerType(),True),\n",
    "    StructField('discount_rate', FloatType(),True),\n",
    "    \n",
    "    StructField(\"rating_average\",FloatType(),True), \n",
    "    StructField(\"review_count\",IntegerType(),True), \n",
    "    StructField(\"productset_group_name\",StringType(),True), \n",
    "    StructField(\"all_time_quantity_sold\",IntegerType(),True),\n",
    "    \n",
    "    StructField(\"description\",StringType(),True), \n",
    "    StructField(\"current_seller\",MapType(StringType(),StringType()),True),\n",
    "    StructField(\"other_sellers\",ArrayType(MapType(StringType(),StringType())),True),\n",
    "    StructField(\"breadcrumbs\",ArrayType(MapType(StringType(),StringType())),True),\n",
    "    StructField(\"specifications\",ArrayType(StructType(\n",
    "                    [\n",
    "                        StructField(\"name\", StringType()),\n",
    "                        StructField(\"attributes\",ArrayType(MapType(StringType(),StringType())),True),\n",
    "                    ]\n",
    "                )),True),\n",
    "\n",
    "    StructField('return_and_exchange_policy', StringType(),True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d73c66b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.withColumn(\"jsonData\",from_json(col(\"value\"),schema)) \\\n",
    "                   .select(\"jsonData.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63ad4572",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('Product')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "020c979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extrct_other_seller(arr,current_id):\n",
    "#     list_id = []\n",
    "#     list_id.append(current_id)\n",
    "#     for item in arr:\n",
    "#         list_id.append(item['id'])\n",
    "#     return list_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e23c58cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.udf.register('extrct_other_seller',extrct_other_seller,ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c42248f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parserAtt(specifications):\n",
    "    result = \"\"\n",
    "    try:\n",
    "        for s in specifications:\n",
    "            for a in s.attributes:\n",
    "                result += a['value']\n",
    "        result = cleanText(result)\n",
    "    except:\n",
    "        return \"\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38f807ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.parserAtt(specifications)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.udf.register('parserAtt',parserAtt,StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d7fb95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# as per recommendation from @freylis, compile once only\n",
    "CLEANR = re.compile('<.*?>') \n",
    "def cleanText(str_raw):\n",
    "    # remove tags html\n",
    "    str_raw = re.sub(CLEANR, ' ', str_raw)\n",
    "\n",
    "    # remove special character\n",
    "    str_raw = re.sub('\\W+', ' ', str_raw)\n",
    "    \n",
    "    # remove number\n",
    "    str_raw = re.sub(\"[0-9]+\", \"\", str_raw)\n",
    "    \n",
    "    # remove space\n",
    "    cleantext = re.sub(\" +\", \" \", str_raw)\n",
    "    return cleantext.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38abd300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.cleanText(str_raw)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.udf.register(\"cleanText\", cleanText,StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a32ec70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# product_clean = spark.sql(\"\"\"\n",
    "#         select id,master_id,sku,price,list_price,original_price,discount,discount_rate,\n",
    "#         rating_average,review_count,productset_group_name,all_time_quantity_sold,\n",
    "#         cleanText(name) name,cleanText(description) description,parserAtt(specifications) specifications,\n",
    "#         current_seller.id seller_id,current_seller.name seller_name,current_seller.store_id seller_store_id,\n",
    "#         cast(current_seller.product_id as int) product_id,\n",
    "#         breadcrumbs[0].name category_name,breadcrumbs[0].category_id category_id,\n",
    "#         explode(extrct_other_seller(other_sellers,current_seller.id)) sellers\n",
    "#         from Product\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4d99ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_clean = spark.sql(\"\"\"\n",
    "        select id,master_id,sku,price,list_price,original_price,discount,discount_rate,\n",
    "        rating_average,review_count,productset_group_name,all_time_quantity_sold,\n",
    "        name, short_description,\n",
    "        cleanText(name) clean_name,cleanText(description) clean_description,parserAtt(specifications) clean_specifications,\n",
    "        breadcrumbs[0].name category_name,breadcrumbs[0].category_id category_id,\n",
    "        current_seller.id seller_id,current_seller.name seller_name,current_seller.store_id seller_store_id,\n",
    "        cast(current_seller.product_id as int) spid\n",
    "        from Product\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7728d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "product_clean.write.partitionBy(\"category_id\").mode('append').parquet('hdfs://namenode:9000/TikiCleaned/Product')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9baf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
