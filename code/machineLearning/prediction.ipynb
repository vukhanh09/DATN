{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4f5710a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import loads\n",
    "from pyspark.sql import SparkSession\n",
    "import warnings\n",
    "import pandas as pd\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# warnings.filterwarnings(action='once')\n",
    "from pyspark.sql.functions import col,from_json,udf,split,explode,lit,array,lower\n",
    "from pyspark.ml.feature import NGram\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType,MapType,FloatType,ArrayType\n",
    "import numpy as np\n",
    "from pyspark.sql import functions as F\n",
    "import re\n",
    "import pickle\n",
    "from itertools import chain\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0912883",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.ml import Pipeline,PipelineModel\n",
    "from pyspark.ml.feature import IDF\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder,CrossValidatorModel\n",
    "from sklearn.metrics import classification_report,accuracy_score,precision_score,recall_score,f1_score\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "882a9502",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.\\\n",
    "        builder.\\\n",
    "        appName(\"ml\").\\\n",
    "        master(\"spark://spark-master:7077\").\\\n",
    "        config(\"spark.executor.memory\", \"1024m\").\\\n",
    "        getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"OFF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbc57e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prediction:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = {}\n",
    "        self.load_model()\n",
    "        self.load_dictionary()\n",
    "        self.load_stop_word()\n",
    "    \n",
    "    def load_model(self):\n",
    "        list_model = ['lr_yes','lr_no','rf_yes','rf_no']\n",
    "        for model_name in list_model:\n",
    "            self.model[model_name] = CrossValidatorModel.load(f'hdfs://namenode:9000/save_model/{model_name}')\n",
    "            \n",
    "        self.model_tfidf = PipelineModel.load(f'hdfs://namenode:9000/save_model/model_tfidf')\n",
    "    \n",
    "    def load_stop_word(self):\n",
    "        with open('data/dict_stop_word.pkl', 'rb') as f:\n",
    "            self.dict_stop_word = pickle.load(f)\n",
    "            \n",
    "        \n",
    "    def load_dictionary(self):\n",
    "        pst_word = {}\n",
    "        ngt_word = {}\n",
    "        with open('vi_sentiment/positive_words_vi.txt','r') as f:\n",
    "            for line in f:\n",
    "                line = line.replace('\\n','')\n",
    "                if line not in pst_word:\n",
    "                    pst_word[line] = 1\n",
    "        with open('vi_sentiment/negative_words_vi.txt','r') as f:\n",
    "            for line in f:\n",
    "                line = line.replace('\\n','')\n",
    "                if line not in pst_word:\n",
    "                    ngt_word[line] = 1\n",
    "        self.pst_word = pst_word\n",
    "        self.ngt_word = ngt_word\n",
    "        \n",
    "    \n",
    "    def cleanText(self,str_raw):\n",
    "        CLEANR = re.compile('<.*?>') \n",
    "        # remove tags html\n",
    "        str_raw = re.sub(CLEANR, ' ', str_raw)\n",
    "\n",
    "        # remove special character\n",
    "        str_raw = re.sub('\\W+', ' ', str_raw)\n",
    "\n",
    "        # remove number\n",
    "        str_raw = re.sub(\"[0-9]+\", \"\", str_raw)\n",
    "\n",
    "        # remove space\n",
    "        cleantext = re.sub(\" +\", \" \", str_raw)\n",
    "        return cleantext.lower()\n",
    "    \n",
    "    \n",
    "    def rule_lexicon_based(self,sentent):\n",
    "        list_token = sentent.split(' ')\n",
    "        pos = 0\n",
    "        neg = 0\n",
    "        for token in list_token:\n",
    "            if token in self.pst_word:\n",
    "                pos += 1\n",
    "            elif token in self.ngt_word:\n",
    "                neg += 1\n",
    "        score = pos - neg\n",
    "        if score > 0:\n",
    "            return 2\n",
    "        elif score == 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def predict(self, txt, model_name='lr',mode='yes'):\n",
    "        dict_stop_word = self.dict_stop_word\n",
    "        \n",
    "        def remove_stop_word(txt):\n",
    "            txt = txt.strip()\n",
    "            ls_words = txt.split()\n",
    "            ls_new_words = []\n",
    "            for word in ls_words:\n",
    "                if dict_stop_word.get(word) == None:\n",
    "                    ls_new_words.append(word)\n",
    "            return ' '.join(ls_new_words)\n",
    "    \n",
    "        clean_text = self.cleanText(txt)\n",
    "        data = [(clean_text,)]\n",
    "        schema = StructType([ \\\n",
    "            StructField(\"clean_content\",StringType(),True),\n",
    "          ])\n",
    "        \n",
    "        input_data = spark.createDataFrame(data=data,schema=schema)\n",
    "        input_data.createOrReplaceTempView('input_data')\n",
    "        spark.udf.register(\"remove_stop_word\", remove_stop_word,StringType())\n",
    "        \n",
    "        input_data = spark.sql(\"\"\"\n",
    "            select remove_stop_word(clean_content) clean_content\n",
    "            from input_data\n",
    "        \"\"\")\n",
    "        \n",
    "        input_data = input_data.select(split(input_data.clean_content, ' ').alias('cmt_token'))\n",
    "        input_idf = model.model_tfidf.transform(input_data)\n",
    "        \n",
    "        \n",
    "        if model_name == 'lr':\n",
    "            if mode == 'yes':\n",
    "                result = self.model['lr_yes'].transform(input_idf).select('prediction').take(1)\n",
    "            else:\n",
    "                result = self.model['lr_no'].transform(input_idf).select('prediction').take(1)\n",
    "        elif model_name == 'rf':\n",
    "            if mode == 'yes':\n",
    "                result = self.model['rf_yes'].transform(input_idf).select('prediction').take(1)\n",
    "            else:\n",
    "                result = self.model['rf_no'].transform(input_idf).select('prediction').take(1)\n",
    "        elif model_name == 'rule_based':\n",
    "            result = self.rule_lexicon_based(clean_text)\n",
    "        \n",
    "        if model_name != 'rule_based':\n",
    "            result = result[0].prediction\n",
    "            \n",
    "        print('='*50)\n",
    "        print('Input data:', txt)\n",
    "        if model_name == 'rule_based':\n",
    "            print(f'{model_name} prediction: ',end='')\n",
    "        else:\n",
    "            print(f'{model_name}_{mode} prediction: ',end='')\n",
    "        if result == 2:\n",
    "            print('Positive')\n",
    "        elif result == 1:\n",
    "            print('Neural')\n",
    "        else:\n",
    "            print('Negative')\n",
    "            \n",
    "            \n",
    "    def prediction(self):\n",
    "        stop = 1\n",
    "        while(stop):\n",
    "            txt = str(input('Type your content: '))\n",
    "            try:\n",
    "                model = int(input('Select model (1: LR, 2:RF, 3: Rule_based): '))\n",
    "                isWeight = 1\n",
    "                if model != 3:\n",
    "                    isWeight = int(input('Weighted model (1: Yes, 2: No): '))\n",
    "\n",
    "                model_mapping = {1:'lr',2:'rf',3:'rule_based'}\n",
    "                isWeight_mapping = {1:'yes',2:'no'}\n",
    "                self.predict(txt,model_mapping[model],isWeight_mapping[isWeight])\n",
    "            except:\n",
    "                self.predict(txt)\n",
    "            try_again = input('Continue to predict (1: Yes, 2: No): ')\n",
    "            if try_again != '1':\n",
    "                stop = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62f24d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d276e3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Type your content:  rất đẹp\n",
      "Select model (1: LR, 2:RF, 3: Rule_based):  1\n",
      "Weighted model (1: Yes, 2: No):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Input data: rất đẹp\n",
      "lr_yes prediction: Positive\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Continue to predict (1: Yes, 2: No):  1\n",
      "Type your content:  rất xấu\n",
      "Select model (1: LR, 2:RF, 3: Rule_based):  1\n",
      "Weighted model (1: Yes, 2: No):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Input data: rất xấu\n",
      "lr_yes prediction: Negative\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Continue to predict (1: Yes, 2: No):  1\n",
      "Type your content:  bình thường\n",
      "Select model (1: LR, 2:RF, 3: Rule_based):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Input data: bình thường\n",
      "rule_based prediction: Neural\n"
     ]
    }
   ],
   "source": [
    "model.prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8fe318",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
