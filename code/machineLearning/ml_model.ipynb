{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e971ecf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import loads\n",
    "from pyspark.sql import SparkSession\n",
    "import warnings\n",
    "import pandas as pd\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from pyspark.sql.functions import col,from_json,udf,split,explode,lit,array,lower\n",
    "from pyspark.ml.feature import NGram\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType,MapType,FloatType,ArrayType\n",
    "import numpy as np\n",
    "import pickle \n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from itertools import chain\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bbf7285",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import IDF\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from sklearn.metrics import classification_report,accuracy_score,precision_score,recall_score,f1_score\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fc1f229",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/01/28 15:44:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.\\\n",
    "        builder.\\\n",
    "        appName(\"ml\").\\\n",
    "        master(\"spark://spark-master:7077\").\\\n",
    "        config(\"spark.executor.memory\", \"2048m\").\\\n",
    "        getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c99f509f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentModel:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.df_test = spark.read.parquet('hdfs://namenode:9000/ml/test_data')\n",
    "        self.df_train = spark.read.parquet('hdfs://namenode:9000/ml/train_data')\n",
    "        self.clean_data()\n",
    "        self.split_content()\n",
    "        self.convert_feature()\n",
    "        self.model = {}\n",
    "        \n",
    "    def getNGram(self,df,n):\n",
    "        ngram = NGram(n=n)\n",
    "        ngram.setInputCol(\"comment_term\")\n",
    "        ngram.setOutputCol(\"nGrams\")\n",
    "        df_nGram = ngram.transform(df)\n",
    "        result_nGram = df_nGram.withColumn('word',explode(df_nGram.nGrams))\\\n",
    "            .groupBy(['word'])\\\n",
    "            .count()\n",
    "        return result_nGram\n",
    "        \n",
    "    def clean_data(self):\n",
    "    \n",
    "        df = self.df_train.withColumn('comment_term',split(self.df_train.clean_content, ' ', -1))\n",
    "\n",
    "        result_nGram = self.getNGram(df,1)\n",
    "        result_nGram.createOrReplaceTempView('result_nGram')\n",
    "        \n",
    "        stop_word = spark.sql(\"\"\"\n",
    "            select word from result_nGram\n",
    "            where count < 10\n",
    "        \"\"\").toPandas()\n",
    "        stop_word = stop_word['word'].to_list()\n",
    "        \n",
    "        dict_stop_word = {x:1 for x in stop_word}\n",
    "        self.dict_stop_word = dict_stop_word\n",
    "        self.df_test.createOrReplaceTempView('df_test')\n",
    "        self.df_train.createOrReplaceTempView('df_train')\n",
    "        \n",
    "        \n",
    "        def remove_stop_word(txt):\n",
    "            txt = txt.strip()\n",
    "            ls_words = txt.split()\n",
    "            ls_new_words = []\n",
    "            for word in ls_words:\n",
    "                if dict_stop_word.get(word) == None:\n",
    "                    ls_new_words.append(word)\n",
    "            return ' '.join(ls_new_words)\n",
    "        spark.udf.register(\"remove_stop_word\", remove_stop_word,StringType())\n",
    "        \n",
    "        self.df_test = spark.sql(\"\"\"\n",
    "            select remove_stop_word(clean_content) clean_content,rating,sentiment,true_label,label \n",
    "            from df_test\n",
    "        \"\"\")\n",
    "        \n",
    "        self.df_train = spark.sql(\"\"\"\n",
    "            select remove_stop_word(clean_content) clean_content,rating,sentiment,label \n",
    "            from df_train\n",
    "        \"\"\")\n",
    "        \n",
    "\n",
    "    \n",
    "    def set_weight(self, w_a = 5,w_b = 5, w_c = 1):\n",
    "        class_weights_spark = {0:w_a,1:w_b,2:w_c}\n",
    "        mapping_expr = F.create_map([F.lit(x) for x in chain(*class_weights_spark.items())])\n",
    "        self.train_idf = self.train_idf.withColumn(\"weight\", mapping_expr.getItem(F.col(\"label\")))\n",
    "        \n",
    "    def split_content(self):\n",
    "        self.train_set = self.df_train.select(split(self.df_train.clean_content, ' ').alias('cmt_token'),'clean_content','rating', 'label')\n",
    "        self.test_set = self.df_test.select(split(self.df_test.clean_content, ' ').alias('cmt_token'),'clean_content','rating', 'label','true_label')\n",
    "    \n",
    "    def convert_feature(self):\n",
    "        count = CountVectorizer(inputCol=\"cmt_token\", outputCol=\"rawFeatures\")\n",
    "        idf = IDF(inputCol=\"rawFeatures\", outputCol=\"featuresTFIDF\")\n",
    "        pipeline = Pipeline(stages=[count, idf])\n",
    "        self.model_tfidf = pipeline.fit(self.train_set)\n",
    "        self.train_idf = self.model_tfidf.transform(self.train_set)\n",
    "        self.test_idf = self.model_tfidf.transform(self.test_set)\n",
    "    \n",
    "    def model_logistic(self,weight):\n",
    "        lr = LogisticRegression(featuresCol = \"featuresTFIDF\")\n",
    "\n",
    "        if weight == True:\n",
    "            paramGrid = ParamGridBuilder()\\\n",
    "                        .addGrid(lr.maxIter, [10, 20, 50])\\\n",
    "                        .addGrid(lr.regParam, [0.1,0.3,0.5])\\\n",
    "                        .addGrid(lr.weightCol,  [\"weight\"])\\\n",
    "                        .build()\n",
    "            \n",
    "        else:\n",
    "            paramGrid = ParamGridBuilder()\\\n",
    "                        .addGrid(lr.maxIter, [10, 20, 50])\\\n",
    "                        .addGrid(lr.regParam, [0.1,0.3,0.5])\\\n",
    "                        .build()\n",
    "\n",
    "        evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "\n",
    "        crossval = CrossValidator(estimator=lr,\n",
    "                                  estimatorParamMaps=paramGrid,\n",
    "                                  evaluator=evaluator,\n",
    "                                  numFolds=5) \n",
    "        \n",
    "        model = crossval.fit(self.train_idf)\n",
    "        if weight == True:\n",
    "            self.model['lr_yes'] = model\n",
    "        else:\n",
    "            self.model['lr_no'] = model\n",
    "        predictions = model.transform(self.test_idf)\n",
    "        return predictions\n",
    "    \n",
    "    def model_rf(self,weight):\n",
    "        trainer = RandomForestClassifier(featuresCol = \"featuresTFIDF\")\n",
    "        if weight == True:\n",
    "            paramGrid = ParamGridBuilder()\\\n",
    "                        .addGrid(trainer.numTrees, [10,20,50])\\\n",
    "                        .addGrid(trainer.maxDepth, [2,6,8])\\\n",
    "                        .addGrid(trainer.minInstancesPerNode, [1,3,5])\\\n",
    "                        .addGrid(trainer.weightCol,  [\"weight\"])\\\n",
    "                        .build()\n",
    "            \n",
    "        else:\n",
    "            paramGrid = ParamGridBuilder()\\\n",
    "                        .addGrid(trainer.numTrees, [10,20,50])\\\n",
    "                        .addGrid(trainer.maxDepth, [2,6,8])\\\n",
    "                        .addGrid(trainer.minInstancesPerNode, [1,3,5])\\\n",
    "                        .build()\n",
    "        \n",
    "        evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "\n",
    "        crossval = CrossValidator(estimator=trainer,\n",
    "                                  estimatorParamMaps=paramGrid,\n",
    "                                  evaluator=evaluator,\n",
    "                                  numFolds=5) \n",
    "        model = crossval.fit(self.train_idf)\n",
    "        if weight == True:\n",
    "            self.model['rf_yes'] = model\n",
    "        else:\n",
    "            self.model['rf_no'] = model\n",
    "        predictions = model.transform(self.test_idf)\n",
    "        return predictions\n",
    "    \n",
    "    def evaluate(self,predictions):\n",
    "        result = predictions.select('true_label', 'prediction')\n",
    "        result = result[['true_label','prediction']].toPandas()\n",
    "        \n",
    "        print(f'accuracy_score: ',accuracy_score(result.true_label, result.prediction))\n",
    "        print(f'prediction: ',precision_score(result.true_label, result.prediction, average='weighted'))\n",
    "        print(f'recall_score: ',recall_score(result.true_label, result.prediction, average='weighted'))\n",
    "        print(f'f1_score: ',f1_score(result.true_label, result.prediction, average='weighted'))\n",
    "        print(classification_report(result.true_label, result.prediction))\n",
    "        \n",
    "    def save_model(self):\n",
    "        list_model = ['lr_yes','lr_no','rf_yes','rf_no']\n",
    "        for model_name in list_model:\n",
    "            self.model[model_name].write().overwrite().save(f'hdfs://namenode:9000/save_model/{model_name}')\n",
    "        \n",
    "        self.model_tfidf.write().overwrite().save(f'hdfs://namenode:9000/save_model/model_tfidf')\n",
    "        \n",
    "        with open('data/dict_stop_word.pkl', 'wb') as f:\n",
    "            pickle.dump(self.dict_stop_word, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0e4cf652",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/01/28 16:42:00 WARN SimpleFunctionRegistry: The function remove_stop_word replaced a previously registered function.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "model = SentimentModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9bb9ae",
   "metadata": {},
   "source": [
    "# Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8b5c381b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb0_cnt = model.train_set.filter(col('label') == 0).count()\n",
    "lb1_cnt = model.train_set.filter(col('label') == 1).count()\n",
    "lb2_cnt = model.train_set.filter(col('label') == 2).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2e19fc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_a = int(lb2_cnt/lb0_cnt)\n",
    "w_b = int(lb2_cnt/lb1_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7de32bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_weight(w_a,w_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb33d0e4",
   "metadata": {},
   "source": [
    "# LogicRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f478453",
   "metadata": {},
   "source": [
    "## Weight balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b211872c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_wb = model.model_logistic(weight=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fdec705d",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.model['lr_yes'].transform(model.train_idf).select(['label','prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6234216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.createOrReplaceTempView('res')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9bfd5d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/01/28 16:53:20 WARN DAGScheduler: Broadcasting large task binary with size 1106.5 KiB\n",
      "[Stage 7245:=================================>                      (3 + 2) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|               acc|\n",
      "+------------------+\n",
      "|0.7811439082250107|\n",
      "+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    select sum(if(label == prediction,1,0))/count(1) acc\n",
    "    from res\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bc2b40cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/01/28 16:53:28 WARN DAGScheduler: Broadcasting large task binary with size 1101.6 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:  0.8171589310829818\n",
      "prediction:  0.8456354036964362\n",
      "recall_score:  0.8171589310829818\n",
      "f1_score:  0.8279409056626836\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.65      0.71       805\n",
      "           1       0.36      0.54      0.43       538\n",
      "           2       0.93      0.90      0.91      3634\n",
      "\n",
      "    accuracy                           0.82      4977\n",
      "   macro avg       0.69      0.70      0.68      4977\n",
      "weighted avg       0.85      0.82      0.83      4977\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(predictions_wb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfb4a20",
   "metadata": {},
   "source": [
    "## No balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a66e430e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/01/28 17:12:07 WARN DAGScheduler: Broadcasting large task binary with size 1139.8 KiB\n",
      "23/01/28 17:12:26 WARN DAGScheduler: Broadcasting large task binary with size 1139.8 KiB\n",
      "23/01/28 17:12:32 WARN DAGScheduler: Broadcasting large task binary with size 1139.8 KiB\n",
      "23/01/28 17:12:43 WARN DAGScheduler: Broadcasting large task binary with size 1139.9 KiB\n",
      "23/01/28 17:12:52 WARN DAGScheduler: Broadcasting large task binary with size 1139.9 KiB\n",
      "23/01/28 17:13:02 WARN DAGScheduler: Broadcasting large task binary with size 1139.9 KiB\n",
      "23/01/28 17:13:24 WARN DAGScheduler: Broadcasting large task binary with size 1140.1 KiB\n",
      "23/01/28 17:13:46 WARN DAGScheduler: Broadcasting large task binary with size 1140.1 KiB\n",
      "23/01/28 17:14:03 WARN DAGScheduler: Broadcasting large task binary with size 1140.0 KiB\n",
      "23/01/28 17:14:26 WARN DAGScheduler: Broadcasting large task binary with size 1139.8 KiB\n",
      "23/01/28 17:14:44 WARN DAGScheduler: Broadcasting large task binary with size 1139.8 KiB\n",
      "23/01/28 17:14:49 WARN DAGScheduler: Broadcasting large task binary with size 1139.8 KiB\n",
      "23/01/28 17:15:00 WARN DAGScheduler: Broadcasting large task binary with size 1139.9 KiB\n",
      "23/01/28 17:15:09 WARN DAGScheduler: Broadcasting large task binary with size 1139.9 KiB\n",
      "23/01/28 17:15:19 WARN DAGScheduler: Broadcasting large task binary with size 1139.9 KiB\n",
      "23/01/28 17:15:41 WARN DAGScheduler: Broadcasting large task binary with size 1140.1 KiB\n",
      "23/01/28 17:15:59 WARN DAGScheduler: Broadcasting large task binary with size 1140.1 KiB\n",
      "23/01/28 17:16:14 WARN DAGScheduler: Broadcasting large task binary with size 1140.0 KiB\n",
      "23/01/28 17:16:37 WARN DAGScheduler: Broadcasting large task binary with size 1139.8 KiB\n",
      "23/01/28 17:16:56 WARN DAGScheduler: Broadcasting large task binary with size 1139.8 KiB\n",
      "23/01/28 17:17:01 WARN DAGScheduler: Broadcasting large task binary with size 1139.8 KiB\n",
      "23/01/28 17:17:12 WARN DAGScheduler: Broadcasting large task binary with size 1139.9 KiB\n",
      "23/01/28 17:17:21 WARN DAGScheduler: Broadcasting large task binary with size 1139.9 KiB\n",
      "23/01/28 17:17:31 WARN DAGScheduler: Broadcasting large task binary with size 1139.9 KiB\n",
      "23/01/28 17:17:53 WARN DAGScheduler: Broadcasting large task binary with size 1140.1 KiB\n",
      "23/01/28 17:18:11 WARN DAGScheduler: Broadcasting large task binary with size 1140.1 KiB\n",
      "23/01/28 17:18:28 WARN DAGScheduler: Broadcasting large task binary with size 1140.0 KiB\n",
      "23/01/28 17:18:50 WARN DAGScheduler: Broadcasting large task binary with size 1139.8 KiB\n",
      "23/01/28 17:19:08 WARN DAGScheduler: Broadcasting large task binary with size 1139.8 KiB\n",
      "23/01/28 17:19:13 WARN DAGScheduler: Broadcasting large task binary with size 1139.8 KiB\n",
      "23/01/28 17:19:23 WARN DAGScheduler: Broadcasting large task binary with size 1139.9 KiB\n",
      "23/01/28 17:19:33 WARN DAGScheduler: Broadcasting large task binary with size 1139.9 KiB\n",
      "23/01/28 17:19:43 WARN DAGScheduler: Broadcasting large task binary with size 1139.9 KiB\n",
      "23/01/28 17:20:04 WARN DAGScheduler: Broadcasting large task binary with size 1140.1 KiB\n",
      "23/01/28 17:20:23 WARN DAGScheduler: Broadcasting large task binary with size 1140.1 KiB\n",
      "23/01/28 17:20:40 WARN DAGScheduler: Broadcasting large task binary with size 1140.0 KiB\n",
      "23/01/28 17:21:03 WARN DAGScheduler: Broadcasting large task binary with size 1139.8 KiB\n",
      "23/01/28 17:21:21 WARN DAGScheduler: Broadcasting large task binary with size 1139.8 KiB\n",
      "23/01/28 17:21:26 WARN DAGScheduler: Broadcasting large task binary with size 1139.8 KiB\n",
      "23/01/28 17:21:36 WARN DAGScheduler: Broadcasting large task binary with size 1139.9 KiB\n",
      "23/01/28 17:21:46 WARN DAGScheduler: Broadcasting large task binary with size 1139.9 KiB\n",
      "23/01/28 17:21:55 WARN DAGScheduler: Broadcasting large task binary with size 1139.9 KiB\n",
      "23/01/28 17:22:18 WARN DAGScheduler: Broadcasting large task binary with size 1140.1 KiB\n",
      "23/01/28 17:22:36 WARN DAGScheduler: Broadcasting large task binary with size 1140.1 KiB\n",
      "23/01/28 17:22:52 WARN DAGScheduler: Broadcasting large task binary with size 1140.0 KiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions_no_wb = model.model_logistic(weight=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "848fe37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:  0.8109302792847096\n",
      "prediction:  0.7753315801526328\n",
      "recall_score:  0.8109302792847096\n",
      "f1_score:  0.7595490082817656\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.52      0.65       805\n",
      "           1       0.41      0.02      0.04       538\n",
      "           2       0.81      0.99      0.89      3634\n",
      "\n",
      "    accuracy                           0.81      4977\n",
      "   macro avg       0.70      0.51      0.53      4977\n",
      "weighted avg       0.78      0.81      0.76      4977\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/01/28 17:23:14 WARN DAGScheduler: Broadcasting large task binary with size 1101.7 KiB\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(predictions_no_wb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0fad46",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436e60ac",
   "metadata": {},
   "source": [
    "## Weight balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5c1a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_predictions_wb = model.model_rf(weight=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f15f5de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/01/29 00:20:57 WARN DAGScheduler: Broadcasting large task binary with size 1000.3 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:  0.7305605786618445\n",
      "prediction:  0.7534757256019623\n",
      "recall_score:  0.7305605786618445\n",
      "f1_score:  0.65939196428338\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.03      0.06       805\n",
      "           1       0.27      0.21      0.24       538\n",
      "           2       0.77      0.96      0.86      3634\n",
      "\n",
      "    accuracy                           0.73      4977\n",
      "   macro avg       0.68      0.40      0.38      4977\n",
      "weighted avg       0.75      0.73      0.66      4977\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(rf_predictions_wb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbc223f",
   "metadata": {},
   "source": [
    "## No balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4613d83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_predictions_no_wb = model.model_rf(weight=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "547b0cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/01/29 07:20:43 WARN DAGScheduler: Broadcasting large task binary with size 1025.4 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:  0.7303596544102873\n",
      "prediction:  0.6949829343597914\n",
      "recall_score:  0.7303596544102873\n",
      "f1_score:  0.6167536903259228\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00       805\n",
      "           1       0.00      0.00      0.00       538\n",
      "           2       0.73      1.00      0.84      3634\n",
      "\n",
      "    accuracy                           0.73      4977\n",
      "   macro avg       0.58      0.33      0.28      4977\n",
      "weighted avg       0.69      0.73      0.62      4977\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(rf_predictions_no_wb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974a7ea8",
   "metadata": {},
   "source": [
    "# Analysis result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4c5b94",
   "metadata": {},
   "source": [
    "## Save model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1e6ac588",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "model.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99032c43",
   "metadata": {},
   "source": [
    "## Best param LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cd945797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='LogisticRegression_60e8183c199d', name='maxIter', doc='max number of iterations (>= 0).'): 10,\n",
       " Param(parent='LogisticRegression_60e8183c199d', name='regParam', doc='regularization parameter (>= 0).'): 0.5,\n",
       " Param(parent='LogisticRegression_60e8183c199d', name='weightCol', doc='weight column name. If this is not set or empty, we treat all instance weights as 1.0.'): 'weight'}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model['lr_yes'].getEstimatorParamMaps()[ np.argmax(model.model['lr_yes'].avgMetrics) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "797c7237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='LogisticRegression_8bc30e75277a', name='maxIter', doc='max number of iterations (>= 0).'): 20,\n",
       " Param(parent='LogisticRegression_8bc30e75277a', name='regParam', doc='regularization parameter (>= 0).'): 0.1}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model['lr_no'].getEstimatorParamMaps()[ np.argmax(model.model['lr_no'].avgMetrics) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3217ee5b",
   "metadata": {},
   "source": [
    "## Best param Rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d642f58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='RandomForestClassifier_5eee6cd5b48a', name='numTrees', doc='Number of trees to train (>= 1).'): 50,\n",
       " Param(parent='RandomForestClassifier_5eee6cd5b48a', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 2,\n",
       " Param(parent='RandomForestClassifier_5eee6cd5b48a', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1,\n",
       " Param(parent='RandomForestClassifier_5eee6cd5b48a', name='weightCol', doc='weight column name. If this is not set or empty, we treat all instance weights as 1.0.'): 'weight'}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model['rf_yes'].getEstimatorParamMaps()[ np.argmax(model.model['rf_yes'].avgMetrics)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7ce53268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='RandomForestClassifier_82cd36a37daf', name='numTrees', doc='Number of trees to train (>= 1).'): 10,\n",
       " Param(parent='RandomForestClassifier_82cd36a37daf', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 8,\n",
       " Param(parent='RandomForestClassifier_82cd36a37daf', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 3}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model['rf_no'].getEstimatorParamMaps()[ np.argmax(model.model['rf_no'].avgMetrics) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607020ba",
   "metadata": {},
   "source": [
    "## Avg accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "aa2b1724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7744775666844111,\n",
       " 0.7752882396209828,\n",
       " 0.7754004232794556,\n",
       " 0.773107796944257,\n",
       " 0.7699993222521928,\n",
       " 0.7689681944196578,\n",
       " 0.7717868728099262,\n",
       " 0.7698096272012491,\n",
       " 0.7689979106322342]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model['lr_yes'].avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e40e1e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8421807601195797,\n",
       " 0.8264344780496538,\n",
       " 0.816763137594442,\n",
       " 0.843301753281112,\n",
       " 0.827020616586316,\n",
       " 0.8171269056732042,\n",
       " 0.8431327155892354,\n",
       " 0.8269242613315927,\n",
       " 0.8170879598842157]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model['lr_no'].avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b2d5985c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.706762339136425,\n",
       " 0.706762339136425,\n",
       " 0.706762339136425,\n",
       " 0.7196760831496611,\n",
       " 0.7243176650319815,\n",
       " 0.7157331072316102,\n",
       " 0.7236021809443158,\n",
       " 0.7111343184476644,\n",
       " 0.7078266258231677,\n",
       " 0.7438364149915796,\n",
       " 0.7438364149915796,\n",
       " 0.7438394905509383,\n",
       " 0.7380920613199236,\n",
       " 0.7439621573280522,\n",
       " 0.734733336678855,\n",
       " 0.7297544013783568,\n",
       " 0.7391717123175789,\n",
       " 0.7308883591316635,\n",
       " 0.7688883407210081,\n",
       " 0.7688883396836772,\n",
       " 0.7688873155394778,\n",
       " 0.7463913108970772,\n",
       " 0.7420297298921222,\n",
       " 0.7535682905868656,\n",
       " 0.7422187133639224,\n",
       " 0.7454319671837563,\n",
       " 0.7494553377675395]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model['rf_yes'].avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0b478062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7905455877839739,\n",
       " 0.7905455877839739,\n",
       " 0.7905455877839739,\n",
       " 0.7905640469187728,\n",
       " 0.7905773455705579,\n",
       " 0.7905507190627796,\n",
       " 0.7906635443762967,\n",
       " 0.7907187434711159,\n",
       " 0.7906132662602084,\n",
       " 0.7905455877839739,\n",
       " 0.7905455877839739,\n",
       " 0.7905455877839739,\n",
       " 0.7905476374182047,\n",
       " 0.7905476404927535,\n",
       " 0.7905455877839739,\n",
       " 0.7905742712335331,\n",
       " 0.790590690661206,\n",
       " 0.7905773436408612,\n",
       " 0.7905455877839739,\n",
       " 0.7905455877839739,\n",
       " 0.7905455877839739,\n",
       " 0.7905455877839739,\n",
       " 0.7905455877839739,\n",
       " 0.7905466145676255,\n",
       " 0.790552756205904,\n",
       " 0.7905568560243882,\n",
       " 0.7905578746992065]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model['rf_no'].avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1c882e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673a4229",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
