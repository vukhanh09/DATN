{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f317f362",
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import loads\n",
    "from pyspark.sql import SparkSession\n",
    "import warnings\n",
    "import pandas as pd\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from pyspark.sql.functions import col,from_json,udf,split,explode,lit,array,lower\n",
    "from pyspark.ml.feature import NGram\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType,MapType,FloatType,ArrayType\n",
    "import numpy as np\n",
    "from pyspark.sql import functions as F\n",
    "import re\n",
    "from itertools import chain\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7a67ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.ml import Pipeline,PipelineModel\n",
    "from pyspark.ml.feature import IDF\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder,CrossValidatorModel\n",
    "from sklearn.metrics import classification_report,accuracy_score,precision_score,recall_score,f1_score\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d651650",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/01/07 14:46:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/01/07 14:46:47 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.\\\n",
    "        builder.\\\n",
    "        appName(\"ml\").\\\n",
    "        master(\"spark://spark-master:7077\").\\\n",
    "        config(\"spark.executor.memory\", \"1024m\").\\\n",
    "        getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2294341a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "crossval = CrossValidatorModel.load('hdfs://namenode:9000/save_model/lr_yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4685fba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prediction:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = {}\n",
    "        self.load_model()\n",
    "        self.load_dictionary()\n",
    "    \n",
    "    def load_model(self):\n",
    "        list_model = ['lr_yes','lr_no','rf_yes','rf_no']\n",
    "        for model_name in list_model:\n",
    "            self.model[model_name] = CrossValidatorModel.load(f'hdfs://namenode:9000/save_model/{model_name}')\n",
    "            \n",
    "        self.model_tfidf = PipelineModel.load(f'hdfs://namenode:9000/save_model/model_tfidf')\n",
    "        \n",
    "        \n",
    "    def load_dictionary(self):\n",
    "        pst_word = {}\n",
    "        ngt_word = {}\n",
    "        with open('vi_sentiment/positive_words_vi.txt','r') as f:\n",
    "            for line in f:\n",
    "                line = line.replace('\\n','')\n",
    "                if line not in pst_word:\n",
    "                    pst_word[line] = 1\n",
    "        with open('vi_sentiment/negative_words_vi.txt','r') as f:\n",
    "            for line in f:\n",
    "                line = line.replace('\\n','')\n",
    "                if line not in pst_word:\n",
    "                    ngt_word[line] = 1\n",
    "        self.pst_word = pst_word\n",
    "        self.ngt_word = ngt_word\n",
    "        \n",
    "    \n",
    "    def cleanText(self,str_raw):\n",
    "        CLEANR = re.compile('<.*?>') \n",
    "        # remove tags html\n",
    "        str_raw = re.sub(CLEANR, ' ', str_raw)\n",
    "\n",
    "        # remove special character\n",
    "        str_raw = re.sub('\\W+', ' ', str_raw)\n",
    "\n",
    "        # remove number\n",
    "        str_raw = re.sub(\"[0-9]+\", \"\", str_raw)\n",
    "\n",
    "        # remove space\n",
    "        cleantext = re.sub(\" +\", \" \", str_raw)\n",
    "        return cleantext.lower()\n",
    "    \n",
    "    \n",
    "    def rule_lexicon_based(self,sentent):\n",
    "        list_token = sentent.split(' ')\n",
    "        pos = 0\n",
    "        neg = 0\n",
    "        for token in list_token:\n",
    "            if token in self.pst_word:\n",
    "                pos += 1\n",
    "            elif token in self.ngt_word:\n",
    "                neg += 1\n",
    "        score = pos - neg\n",
    "        if score > 0:\n",
    "            return 2\n",
    "        elif score == 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def predict(self, txt, model_name='lr',mode='yes'):\n",
    "        clean_text = self.cleanText(txt)\n",
    "        data = [(clean_text,)]\n",
    "        schema = StructType([ \\\n",
    "            StructField(\"clean_text\",StringType(),True),\n",
    "          ])\n",
    "        \n",
    "        input_data = spark.createDataFrame(data=data,schema=schema)\n",
    "        input_data = input_data.select(split(input_data.clean_text, ' ').alias('cmt_token'))\n",
    "        input_idf = model.model_tfidf.transform(input_data)\n",
    "        \n",
    "        \n",
    "        if model_name == 'lr':\n",
    "            if mode == 'yes':\n",
    "                result = self.model['lr_yes'].transform(input_idf).select('prediction').take(1)\n",
    "            else:\n",
    "                result = self.model['lr_no'].transform(input_idf).select('prediction').take(1)\n",
    "        elif model_name == 'rf':\n",
    "            if mode == 'yes':\n",
    "                result = self.model['rf_yes'].transform(input_idf).select('prediction').take(1)\n",
    "            else:\n",
    "                result = self.model['rf_no'].transform(input_idf).select('prediction').take(1)\n",
    "        elif model_name == 'rule_based':\n",
    "            result = self.rule_lexicon_based(clean_text)\n",
    "        \n",
    "        if model_name != 'rule_based':\n",
    "            result = result[0].prediction\n",
    "            \n",
    "        print('Input data:', txt)\n",
    "        print('='*40)\n",
    "        print('Prediction: ')\n",
    "        if result == 2:\n",
    "            print('Positive')\n",
    "        elif result == 1:\n",
    "            print('Neural')\n",
    "        else:\n",
    "            print('Negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "91502fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "fff83aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = 'đẹp nhưng ngắn quá'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ae814dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data: đẹp nhưng ngắn quá\n",
      "========================================\n",
      "Prediction: \n",
      "Neural\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/01/07 15:44:43 WARN DAGScheduler: Broadcasting large task binary with size 1401.0 KiB\n",
      "23/01/07 15:44:43 WARN DAGScheduler: Broadcasting large task binary with size 1401.0 KiB\n"
     ]
    }
   ],
   "source": [
    "model.predict(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "cb28d32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data: đẹp nhưng ngắn quá\n",
      "========================================\n",
      "Prediction: \n",
      "Positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/01/07 15:44:45 WARN DAGScheduler: Broadcasting large task binary with size 1401.0 KiB\n",
      "23/01/07 15:44:45 WARN DAGScheduler: Broadcasting large task binary with size 1401.0 KiB\n"
     ]
    }
   ],
   "source": [
    "model.predict(txt,'lr','no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d06ea8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data: đẹp nhưng ngắn quá\n",
      "========================================\n",
      "Prediction: \n",
      "Neural\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/01/07 15:44:46 WARN DAGScheduler: Broadcasting large task binary with size 1430.4 KiB\n",
      "23/01/07 15:44:46 WARN DAGScheduler: Broadcasting large task binary with size 1430.4 KiB\n"
     ]
    }
   ],
   "source": [
    "model.predict(txt,'rf','yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "00a2c21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data: đẹp nhưng ngắn quá\n",
      "========================================\n",
      "Prediction: \n",
      "Positive\n"
     ]
    }
   ],
   "source": [
    "model.predict(txt,'rf','no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "8c0890e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data: đẹp nhưng ngắn quá\n",
      "========================================\n",
      "Prediction: \n",
      "Positive\n"
     ]
    }
   ],
   "source": [
    "model.predict(txt,'rule_based','no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae1383c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650bc38e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
