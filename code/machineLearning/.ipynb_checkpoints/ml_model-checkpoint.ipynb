{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1674fee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import loads\n",
    "from pyspark.sql import SparkSession\n",
    "import warnings\n",
    "import pandas as pd\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from pyspark.sql.functions import col,from_json,udf,split,explode,lit,array,lower\n",
    "from pyspark.ml.feature import NGram\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType,MapType,FloatType,ArrayType\n",
    "import numpy as np\n",
    "from pyspark.sql import functions as F\n",
    "from itertools import chain\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51882054",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import IDF\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from sklearn.metrics import classification_report,accuracy_score,precision_score,recall_score,f1_score\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a01ba415",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/01/05 16:26:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.\\\n",
    "        builder.\\\n",
    "        appName(\"ml\").\\\n",
    "        master(\"spark://spark-master:7077\").\\\n",
    "        config(\"spark.executor.memory\", \"1024m\").\\\n",
    "        getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce0da7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentModel:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.df_test = spark.read.parquet('hdfs://namenode:9000/ml/test_data')\n",
    "        self.df_train = spark.read.parquet('hdfs://namenode:9000/ml/train_data')\n",
    "        self.split_content()\n",
    "        self.convert_feature()\n",
    "        self.model = {}\n",
    "        \n",
    "    def set_weight(self, w_a = 5,w_b = 5, w_c = 1):\n",
    "        class_weights_spark = {0:w_a,1:w_b,2:w_c}\n",
    "        mapping_expr = F.create_map([F.lit(x) for x in chain(*class_weights_spark.items())])\n",
    "        self.train_idf = self.train_idf.withColumn(\"weight\", mapping_expr.getItem(F.col(\"label\")))\n",
    "        \n",
    "    def split_content(self):\n",
    "        self.train_set = self.df_train.select(split(self.df_train.clean_content, ' ').alias('cmt_token'),'clean_content','rating', 'label')\n",
    "        self.test_set = self.df_test.select(split(self.df_test.clean_content, ' ').alias('cmt_token'),'clean_content','rating', 'label','true_label')\n",
    "    \n",
    "    def convert_feature(self):\n",
    "        count = CountVectorizer(inputCol=\"cmt_token\", outputCol=\"rawFeatures\")\n",
    "        idf = IDF(inputCol=\"rawFeatures\", outputCol=\"featuresTFIDF\",minDocFreq=2)\n",
    "        pipeline = Pipeline(stages=[count, idf])\n",
    "        self.model_tfidf = pipeline.fit(self.train_set)\n",
    "        self.train_idf = self.model_tfidf.transform(self.train_set)\n",
    "        self.test_idf = self.model_tfidf.transform(self.test_set)\n",
    "    \n",
    "    def model_logistic(self,weight):\n",
    "        if weight == True:\n",
    "            lr = LogisticRegression(maxIter=20,featuresCol = \"featuresTFIDF\", tol=1E-6,regParam=0.3, elasticNetParam=0,weightCol=\"weight\")\n",
    "        else:\n",
    "            lr = LogisticRegression(maxIter=20,featuresCol = \"featuresTFIDF\", tol=1E-6,regParam=0.3, elasticNetParam=0)\n",
    "        \n",
    "        paramGrid = ParamGridBuilder()\\\n",
    "                    .addGrid(lr.maxIter, [10, 20, 50])\\\n",
    "                    .addGrid(lr.regParam, [0.1,0.3,0.5])\\\n",
    "                    .addGrid(lr.elasticNetParam,  [0.0, 0.1, 0.2])\\\n",
    "                    .build()\n",
    "        evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "\n",
    "        crossval = CrossValidator(estimator=lr,\n",
    "                                  estimatorParamMaps=paramGrid,\n",
    "                                  evaluator=evaluator,\n",
    "                                  numFolds=5) \n",
    "        model = crossval.fit(self.train_idf)\n",
    "        if weight == True:\n",
    "            self.model['lr_yes'] = model\n",
    "        else:\n",
    "            self.model['lr_no'] = model\n",
    "        predictions = model.transform(self.test_idf)\n",
    "        return predictions\n",
    "    \n",
    "    def model_rf(self,weight):\n",
    "        if weight == True:\n",
    "            trainer = RandomForestClassifier(featuresCol = \"featuresTFIDF\",weightCol=\"weight\")\n",
    "        else:\n",
    "            trainer = RandomForestClassifier(featuresCol = \"featuresTFIDF\")\n",
    "            \n",
    "        paramGrid = ParamGridBuilder()\\\n",
    "                .addGrid(trainer.numTrees, [10,20,50])\\\n",
    "               .addGrid(trainer.maxDepth, [2,6,8])\\\n",
    "               .addGrid(trainer.minInstancesPerNode, [1,3,5])\\\n",
    "               .build()\n",
    "        \n",
    "        evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "\n",
    "        crossval = CrossValidator(estimator=trainer,\n",
    "                                  estimatorParamMaps=paramGrid,\n",
    "                                  evaluator=evaluator,\n",
    "                                  numFolds=5) \n",
    "        model = crossval.fit(self.train_idf)\n",
    "        if weight == True:\n",
    "            self.model['rf_yes'] = model\n",
    "        else:\n",
    "            self.model['rf_no'] = model\n",
    "        predictions = model.transform(self.test_idf)\n",
    "        return predictions\n",
    "    \n",
    "    def evaluate(self,predictions):\n",
    "        result = predictions.select('true_label', 'prediction')\n",
    "        result = result[['true_label','prediction']].toPandas()\n",
    "        \n",
    "        print(f'accuracy_score: ',accuracy_score(result.true_label, result.prediction))\n",
    "        print(f'prediction: ',precision_score(result.true_label, result.prediction, average='weighted'))\n",
    "        print(f'recall_score: ',recall_score(result.true_label, result.prediction, average='weighted'))\n",
    "        print(f'f1_score: ',f1_score(result.true_label, result.prediction, average='weighted'))\n",
    "        print(classification_report(result.true_label, result.prediction))\n",
    "        \n",
    "    def save_model(self):\n",
    "        list_model = ['lr_yes','lr_no','rf_yes','rf_no']\n",
    "        for model_name in list_model:\n",
    "            self.model[model_name].save(f'hdfs://namenode:9000/save_model/{model_name}')\n",
    "        \n",
    "        self.model_tfidf.save(f'hdfs://namenode:9000/save_model/model_tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f25a44c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "model = SentimentModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e9df89",
   "metadata": {},
   "source": [
    "# Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54a3d687",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb0_cnt = model.train_set.filter(col('label') == 0).count()\n",
    "lb1_cnt = model.train_set.filter(col('label') == 1).count()\n",
    "lb2_cnt = model.train_set.filter(col('label') == 2).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9ceb5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_a = int(lb2_cnt/lb0_cnt)\n",
    "w_b = int(lb2_cnt/lb1_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73c23a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_weight(w_a,w_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de85c472",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072a54b1",
   "metadata": {},
   "source": [
    "## Weight balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488f308e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_wb = model.model_logistic(weight=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e16e9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/01/05 16:59:45 WARN DAGScheduler: Broadcasting large task binary with size 1402.7 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:  0.8071127185051236\n",
      "prediction:  0.8380121130560214\n",
      "recall_score:  0.8071127185051236\n",
      "f1_score:  0.8191898941593666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.65      0.71       805\n",
      "           1       0.33      0.51      0.40       538\n",
      "           2       0.93      0.89      0.91      3634\n",
      "\n",
      "    accuracy                           0.81      4977\n",
      "   macro avg       0.68      0.68      0.67      4977\n",
      "weighted avg       0.84      0.81      0.82      4977\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(predictions_wb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d42088a",
   "metadata": {},
   "source": [
    "## No balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda2cbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_no_wb = model.model_logistic(weight=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "865cacdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/01/05 17:32:05 WARN DAGScheduler: Broadcasting large task binary with size 1402.8 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:  0.7996785211975085\n",
      "prediction:  0.7822861675903823\n",
      "recall_score:  0.7996785211975085\n",
      "f1_score:  0.7437892326495242\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.44      0.59       805\n",
      "           1       0.55      0.02      0.04       538\n",
      "           2       0.79      0.99      0.88      3634\n",
      "\n",
      "    accuracy                           0.80      4977\n",
      "   macro avg       0.74      0.48      0.50      4977\n",
      "weighted avg       0.78      0.80      0.74      4977\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(predictions_no_wb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbad139",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0938b8",
   "metadata": {},
   "source": [
    "## Weight balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fc09b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_predictions_wb = model.model_rf(weight=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "479d706a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/01/06 04:43:29 WARN DAGScheduler: Broadcasting large task binary with size 1423.6 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:  0.6978099256580269\n",
      "prediction:  0.8142869090693283\n",
      "recall_score:  0.6978099256580269\n",
      "f1_score:  0.7217519529565698\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.26      0.40       805\n",
      "           1       0.20      0.53      0.29       538\n",
      "           2       0.90      0.82      0.86      3634\n",
      "\n",
      "    accuracy                           0.70      4977\n",
      "   macro avg       0.65      0.54      0.52      4977\n",
      "weighted avg       0.81      0.70      0.72      4977\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(rf_predictions_wb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43f9a0e",
   "metadata": {},
   "source": [
    "## No balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e047ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_predictions_no_wb = model.model_rf(weight=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19b80814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:  0.7301587301587301\n",
      "prediction:  0.5331317712270093\n",
      "recall_score:  0.7301587301587301\n",
      "f1_score:  0.6162807630697539\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       805\n",
      "           1       0.00      0.00      0.00       538\n",
      "           2       0.73      1.00      0.84      3634\n",
      "\n",
      "    accuracy                           0.73      4977\n",
      "   macro avg       0.24      0.33      0.28      4977\n",
      "weighted avg       0.53      0.73      0.62      4977\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(rf_predictions_no_wb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d9663b",
   "metadata": {},
   "source": [
    "# Analysis result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1813025d",
   "metadata": {},
   "source": [
    "## Save model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e93ab71",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec13c5c6",
   "metadata": {},
   "source": [
    "## Best param LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8dd6489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='LogisticRegression_ee405948cf7c', name='maxIter', doc='max number of iterations (>= 0).'): 10,\n",
       " Param(parent='LogisticRegression_ee405948cf7c', name='regParam', doc='regularization parameter (>= 0).'): 0.1,\n",
       " Param(parent='LogisticRegression_ee405948cf7c', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model['lr_yes'].getEstimatorParamMaps()[ np.argmax(model.model['lr_yes'].avgMetrics) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4384758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='LogisticRegression_36f49e359ee4', name='maxIter', doc='max number of iterations (>= 0).'): 20,\n",
       " Param(parent='LogisticRegression_36f49e359ee4', name='regParam', doc='regularization parameter (>= 0).'): 0.1,\n",
       " Param(parent='LogisticRegression_36f49e359ee4', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model['lr_no'].getEstimatorParamMaps()[ np.argmax(model.model['lr_no'].avgMetrics) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0566dba4",
   "metadata": {},
   "source": [
    "## Best param Rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee8571f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='RandomForestClassifier_19268b04e044', name='numTrees', doc='Number of trees to train (>= 1).'): 50,\n",
       " Param(parent='RandomForestClassifier_19268b04e044', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 8,\n",
       " Param(parent='RandomForestClassifier_19268b04e044', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 5}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model['rf_yes'].getEstimatorParamMaps()[ np.argmax(model.model['rf_yes'].avgMetrics) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1180fd0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='RandomForestClassifier_9f7ae89f4864', name='numTrees', doc='Number of trees to train (>= 1).'): 10,\n",
       " Param(parent='RandomForestClassifier_9f7ae89f4864', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 8,\n",
       " Param(parent='RandomForestClassifier_9f7ae89f4864', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model['rf_no'].getEstimatorParamMaps()[ np.argmax(model.model['rf_no'].avgMetrics) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f074130",
   "metadata": {},
   "source": [
    "## Avg accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3ee54e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8035241254071251,\n",
       " 0.7683423426889808,\n",
       " 0.6972582962713498,\n",
       " 0.8006572715530759,\n",
       " 0.6635146579721681,\n",
       " 0.578808415620367,\n",
       " 0.7982104886786365,\n",
       " 0.5971425076992609,\n",
       " 0.399380499326747,\n",
       " 0.7985474107130952,\n",
       " 0.7459278516865715,\n",
       " 0.6992864664188447,\n",
       " 0.7888302059647893,\n",
       " 0.6658135391330271,\n",
       " 0.5682901734075071,\n",
       " 0.7840285206222166,\n",
       " 0.6074315623156624,\n",
       " 0.399380499326747,\n",
       " 0.7962262538072673,\n",
       " 0.7453606400791458,\n",
       " 0.6992929867733968,\n",
       " 0.7886265545327096,\n",
       " 0.6655905387900842,\n",
       " 0.5680833126628535,\n",
       " 0.7841037490813189,\n",
       " 0.6076102459215886,\n",
       " 0.399380499326747]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model['lr_yes'].avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "176807c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8723771621025318,\n",
       " 0.8455521329967675,\n",
       " 0.8320283526800031,\n",
       " 0.8580375138735298,\n",
       " 0.8248658656545842,\n",
       " 0.8233104207854742,\n",
       " 0.8490610612224072,\n",
       " 0.8233292651201483,\n",
       " 0.8233104207854742,\n",
       " 0.873914207825562,\n",
       " 0.8461983352577356,\n",
       " 0.8329911299234869,\n",
       " 0.85907582829636,\n",
       " 0.8248878321839845,\n",
       " 0.8233104207854742,\n",
       " 0.8499297000781764,\n",
       " 0.8233292651201483,\n",
       " 0.8233104207854742,\n",
       " 0.8737103421528526,\n",
       " 0.8461699137588943,\n",
       " 0.8330040698441363,\n",
       " 0.8587810412418978,\n",
       " 0.8248878178899388,\n",
       " 0.8233104207854742,\n",
       " 0.8497666934215311,\n",
       " 0.8233292651201483,\n",
       " 0.8233104207854742]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model['lr_no'].avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9b0c9cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4770127269181251,\n",
       " 0.47700020053802666,\n",
       " 0.4770064973707198,\n",
       " 0.5830843515623017,\n",
       " 0.5768870095241461,\n",
       " 0.5638718870016706,\n",
       " 0.60932291180402,\n",
       " 0.6114060284105972,\n",
       " 0.5794341983061156,\n",
       " 0.5578252973982392,\n",
       " 0.5578190537394551,\n",
       " 0.5578221755688471,\n",
       " 0.6443740427015484,\n",
       " 0.6423338060847188,\n",
       " 0.6379585422644761,\n",
       " 0.6711655208604128,\n",
       " 0.6628006066318488,\n",
       " 0.6593658725019277,\n",
       " 0.6307324738008341,\n",
       " 0.6307293710921875,\n",
       " 0.6307388668756267,\n",
       " 0.6845211527667706,\n",
       " 0.6819409392275879,\n",
       " 0.6861957896677083,\n",
       " 0.6947141017833175,\n",
       " 0.696715828040569,\n",
       " 0.7022719143131806]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model['rf_yes'].avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "04f98562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8233104207854742,\n",
       " 0.8233104207854742,\n",
       " 0.8233104207854742,\n",
       " 0.8233261136955721,\n",
       " 0.8233198255188479,\n",
       " 0.8233104207854742,\n",
       " 0.8233889328814579,\n",
       " 0.823319811224802,\n",
       " 0.8233386166796128,\n",
       " 0.8233104207854742,\n",
       " 0.8233104207854742,\n",
       " 0.8233104207854742,\n",
       " 0.8233104207854742,\n",
       " 0.8233135692018207,\n",
       " 0.8233104207854742,\n",
       " 0.8233104207854742,\n",
       " 0.8233292915244357,\n",
       " 0.8233167176181675,\n",
       " 0.8233104207854742,\n",
       " 0.8233104207854742,\n",
       " 0.8233104207854742,\n",
       " 0.8233104207854742,\n",
       " 0.8233104207854742,\n",
       " 0.8233104207854742,\n",
       " 0.8233104207854742,\n",
       " 0.8233104207854742,\n",
       " 0.8233104207854742]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model['rf_no'].avgMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345dd9f3",
   "metadata": {},
   "source": [
    "# preference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1a252f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = 'dép đẹp vừa chân rất hài lòng'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b64d9593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# as per recommendation from @freylis, compile once only\n",
    "CLEANR = re.compile('<.*?>') \n",
    "def cleanText(str_raw):\n",
    "    # remove tags html\n",
    "    str_raw = re.sub(CLEANR, ' ', str_raw)\n",
    "\n",
    "    # remove special character\n",
    "    str_raw = re.sub('\\W+', ' ', str_raw)\n",
    "    \n",
    "    # remove number\n",
    "    str_raw = re.sub(\"[0-9]+\", \"\", str_raw)\n",
    "    \n",
    "    # remove space\n",
    "    cleantext = re.sub(\" +\", \" \", str_raw)\n",
    "    return cleantext.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "24b9332a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text = cleanText(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8de6c4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(clean_text,)]\n",
    "schema = StructType([ \\\n",
    "    StructField(\"clean_text\",StringType(),True),\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dcf6b815",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = spark.createDataFrame(data=data,schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a0c0c0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    " input_data = input_data.select(split(input_data.clean_text, ' ').alias('cmt_token'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1158b3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_idf = model.model_tfidf.transform(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "83a99e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/01/07 12:10:31 WARN DAGScheduler: Broadcasting large task binary with size 1401.4 KiB\n",
      "23/01/07 12:10:31 WARN DAGScheduler: Broadcasting large task binary with size 1401.4 KiB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(prediction=2.0)]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model['lr_yes'].transform(input_idf).select('prediction').take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f23151",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
